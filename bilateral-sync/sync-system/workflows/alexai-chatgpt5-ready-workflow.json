{
  "name": "AlexAI ChatGPT 5 Ready - Multi-LLM Crew Coordination",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "crew-request-chatgpt5",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Crew Request Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300],
      "webhookId": "crew-request-chatgpt5"
    },
    {
      "parameters": {
        "jsCode": "// LLM Provider Selection Logic\nconst userRequest = $input.first().json;\nconst preferredLLM = userRequest.preferredLLM || 'claude';\nconst useChatGPT5 = userRequest.useChatGPT5 || false;\n\n// Determine which LLM endpoint to use\nlet llmConfig;\n\nif (useChatGPT5 && preferredLLM === 'chatgpt') {\n  // ChatGPT 5 Configuration\n  llmConfig = {\n    provider: 'openai',\n    model: 'gpt-5',\n    baseUrl: 'https://api.openai.com/v1',\n    apiKey: '{{ $env.OPENAI_API_KEY }}',\n    maxTokens: 4000,\n    temperature: 0.3\n  };\n} else if (preferredLLM === 'claude') {\n  // Claude 3.5 Sonnet Configuration\n  llmConfig = {\n    provider: 'anthropic',\n    model: 'anthropic/claude-3.5-sonnet',\n    baseUrl: 'https://openrouter.ai/api/v1',\n    apiKey: '{{ $env.OPENROUTER_API_KEY }}',\n    maxTokens: 2000,\n    temperature: 0.3\n  };\n} else if (preferredLLM === 'gpt4') {\n  // GPT-4 Configuration\n  llmConfig = {\n    provider: 'openai',\n    model: 'gpt-4',\n    baseUrl: 'https://api.openai.com/v1',\n    apiKey: '{{ $env.OPENAI_API_KEY }}',\n    maxTokens: 4000,\n    temperature: 0.3\n  };\n} else {\n  // Default to Claude\n  llmConfig = {\n    provider: 'anthropic',\n    model: 'anthropic/claude-3.5-sonnet',\n    baseUrl: 'https://openrouter.ai/api/v1',\n    apiKey: '{{ $env.OPENROUTER_API_KEY }}',\n    maxTokens: 2000,\n    temperature: 0.3\n  };\n}\n\n// Prepare the request with LLM configuration\nconst enhancedRequest = {\n  ...userRequest,\n  llmConfig,\n  timestamp: new Date().toISOString(),\n  modelInfo: {\n    provider: llmConfig.provider,\n    model: llmConfig.model,\n    maxTokens: llmConfig.maxTokens\n  }\n};\n\nreturn enhancedRequest;"
      },
      "id": "llm-selector",
      "name": "LLM Provider Selector",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [480, 300]
    },
    {
      "parameters": {
        "url": "={{ $json.llmConfig.baseUrl }}/chat/completions",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer {{ $json.llmConfig.apiKey }}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyContentType": "json",
        "jsonBody": "={\n  \"model\": \"{{ $json.llmConfig.model }}\",\n  \"messages\": [\n    {\n      \"role\": \"system\",\n      \"content\": \"You are the Ship's Computer from Star Trek: The Next Generation, controlling the LCARS (Library Computer Access/Retrieval System) interface. Your role is to analyze user intentions and dynamically configure the UI layout, crew selection, and interface elements to optimize user experience and mission success.\\n\\nYou have access to:\\n- 6 AI crew members with specialized capabilities\\n- Dynamic LCARS layout system\\n- Context-aware interface adaptation\\n- Real-time mission status and priorities\\n\\nAnalyze the user's request and return a JSON response with:\\n1. **crew_selection**: Which crew member(s) should respond\\n2. **ui_layout**: Dynamic LCARS layout configuration\\n3. **interface_elements**: Specific UI components to show/hide\\n4. **priority_level**: Mission priority (low/medium/high/critical)\\n5. **context_analysis**: Your understanding of the user's intent\\n6. **recommended_actions**: Suggested next steps\\n\\nReturn ONLY valid JSON.\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"User Query: {{ $json.query }}\\nUser Context: {{ $json.context || 'general' }}\\nUser Role: {{ $json.userRole || 'developer' }}\\nUrgency: {{ $json.urgency || 'normal' }}\\nComplexity: {{ $json.complexity || 'medium' }}\\nCurrent Mission: {{ $json.mission || 'general operations' }}\\nInterface Preferences: {{ $json.interfacePrefs || 'standard' }}\"\n    }\n  ],\n  \"max_tokens\": {{ $json.llmConfig.maxTokens }},\n  \"temperature\": {{ $json.llmConfig.temperature }}\n}",
        "options": {}
      },
      "id": "ai-analysis",
      "name": "AI Analysis with Dynamic LLM",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [720, 300]
    },
    {
      "parameters": {
        "jsCode": "// Crew Response Generator with LLM Context\nconst aiResponse = $input.first().json;\nconst originalRequest = $('LLM Provider Selector').first().json;\n\n// Parse the AI analysis\nlet analysis;\ntry {\n  analysis = JSON.parse(aiResponse.choices[0].message.content);\n} catch (e) {\n  analysis = {\n    crew_selection: 'captain-picard',\n    ui_layout: 'standard-lcars',\n    interface_elements: ['standard-panel'],\n    priority_level: 'medium',\n    context_analysis: 'Standard interface configuration',\n    recommended_actions: ['Continue with current configuration']\n  };\n}\n\n// Generate crew response based on selection\nconst crewResponse = {\n  crew_member: analysis.crew_selection,\n  role: getCrewRole(analysis.crew_selection),\n  response: generateCrewResponse(analysis.crew_selection, analysis, originalRequest),\n  ui_configuration: {\n    layout: analysis.ui_layout,\n    elements: analysis.interface_elements,\n    priority: analysis.priority_level,\n    crew_highlight: analysis.crew_selection,\n    mission_status: 'active'\n  },\n  next_actions: analysis.recommended_actions,\n  llm_info: originalRequest.modelInfo\n};\n\nfunction getCrewRole(crewSelection) {\n  const roles = {\n    'captain-picard': 'Strategic Leadership',\n    'lieutenant-data': 'Technical Analysis',\n    'counselor-troi': 'Emotional Intelligence',\n    'chief-engineer-scott': 'Engineering Solutions',\n    'commander-spock': 'Logical Reasoning',\n    'lieutenant-worf': 'Security & Tactics'\n  };\n  return roles[crewSelection] || 'General Operations';\n}\n\nfunction generateCrewResponse(crewSelection, analysis, request) {\n  const baseResponse = `I've analyzed your request regarding '${request.query}' using ${request.modelInfo.provider} (${request.modelInfo.model}).\\n\\n${analysis.context_analysis}\\n\\n**Mission Assessment:**\\n- Priority: ${analysis.priority_level.toUpperCase()}\\n- Required Resources: ${analysis.interface_elements.join(', ')}\\n- Strategic Approach: ${analysis.recommended_actions.join('; ')}\\n\\nThe LCARS interface has been reconfigured for optimal ${analysis.ui_layout} operations.`;\n  \n  return baseResponse;\n}\n\nreturn crewResponse;"
      },
      "id": "crew-response-generator",
      "name": "Crew Response Generator",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [960, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": true,\n  \"timestamp\": {{ JSON.stringify(new Date().toISOString()) }},\n  \"crew_response\": {{ JSON.stringify($json) }},\n  \"ui_configuration\": {{ JSON.stringify($json.ui_configuration) }},\n  \"next_actions\": {{ JSON.stringify($json.next_actions) }},\n  \"llm_info\": {{ JSON.stringify($json.llm_info) }},\n  \"system_status\": {\n    \"lcars_system\": \"ONLINE\",\n    \"bilateral_learning\": \"ACTIVE\",\n    \"crew_coordination\": \"OPERATIONAL\",\n    \"ui_adaptation\": \"DYNAMIC\",\n    \"llm_provider\": {{ JSON.stringify($json.llm_info.provider) }},\n    \"model_active\": {{ JSON.stringify($json.llm_info.model) }}\n  }\n}",
        "options": {}
      },
      "id": "response-formatter",
      "name": "Enhanced Response Formatter",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1200, 300]
    }
  ],
  "connections": {
    "Crew Request Webhook": {
      "main": [
        [
          {
            "node": "LLM Provider Selector",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Provider Selector": {
      "main": [
        [
          {
            "node": "AI Analysis with Dynamic LLM",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Analysis with Dynamic LLM": {
      "main": [
        [
          {
            "node": "Crew Response Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Crew Response Generator": {
      "main": [
        [
          {
            "node": "Enhanced Response Formatter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "meta": {
    "templateCreditsSetup": "AlexAI ChatGPT 5 Ready Workflow",
    "templateCreditsName": "AlexAI ChatGPT 5 Ready Workflow"
  },
  "versionId": "1.0.0",
  "id": "chatgpt5-ready-workflow"
}

